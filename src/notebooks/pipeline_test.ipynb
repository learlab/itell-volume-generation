{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# iTELL Volume Generation Pipeline - Testing Notebook\n",
    "\n",
    "Test all three prompt strategies against your input PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "✓ Working directory: /Users/kalidindiadithya/Documents/itell-volume-generation/src/notebooks\n",
      "✓ Project root: /Users/kalidindiadithya/Documents/itell-volume-generation\n",
      "✓ .env file path: /Users/kalidindiadithya/Documents/itell-volume-generation/.env\n",
      "✓ .env file exists: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "# Force reload of the module to pick up changes\n",
    "import importlib\n",
    "if 'pipeline.gemini_client' in sys.modules:\n",
    "    importlib.reload(sys.modules['pipeline.gemini_client'])\n",
    "\n",
    "from pipeline.gemini_client import OpenAIClient, GeminiClient\n",
    "from pipeline.extract_images import ExtractImages\n",
    "from pipeline.utils import (\n",
    "    build_conversion_prompt,\n",
    "    encode_pdf_to_base64,\n",
    "    format_image_metadata,\n",
    "    load_guide_instructions,\n",
    "    load_reference_json,\n",
    "    select_reference_example,\n",
    ")\n",
    "\n",
    "project_root = parent_dir.parent\n",
    "\n",
    "# Load environment variables with override=True to refresh any cached values\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"✓ Working directory: {Path.cwd()}\")\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ .env file path: {env_path}\")\n",
    "print(f\"✓ .env file exists: {env_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the PDF file path to test different input documents. Output files will be named: `itell_{PDF_NAME}_{STRATEGY}.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: input.pdf\n",
      "Provider: gemini\n",
      "Model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "PDF_PATH = project_root / \"data\" / \"input.pdf\"\n",
    "IMAGE_DIR = project_root / \"data\" / \"extractedimages\"\n",
    "BASE_STRATEGY_PATH = project_root / \"generation_modes_modular\" / \"base_strategy3.md\"\n",
    "\n",
    "GENERATION_MODES_PATH = [\n",
    "    project_root / \"generation_modes_modular\" / \"adaptive.md\",\n",
    "    project_root / \"generation_modes_modular\" / \"condensed.md\",\n",
    "    project_root / \"generation_modes_modular\" / \"faithful.md\",\n",
    "    project_root / \"generation_modes_modular\" / \"interaction-heavy.md\",\n",
    "    project_root / \"generation_modes_modular\" / \"simplified.md\"\n",
    "]\n",
    "\n",
    "REFERENCE_JSON_PATH = project_root / \"prompts/reference.json\" #used reference-1 for psychology chapter testing\n",
    "PDF_NAME = PDF_PATH.stem\n",
    "\n",
    "# Set provider: \"gemini\" or \"openrouter\"\n",
    "PROVIDER = \"gemini\"\n",
    "\n",
    "if PROVIDER == \"gemini\":\n",
    "    MODEL = os.getenv(\"GEMINI_MODEL\") or \"gemini-2.5-flash\"\n",
    "    MAX_TOKENS = 65536  # Increased from 8192 to support larger volume structures\n",
    "elif PROVIDER == \"openrouter\":\n",
    "    MODEL = os.getenv(\"OPENROUTER_MODEL\") or \"google/gemini-2.5-flash\"\n",
    "    MAX_TOKENS = 99999\n",
    "else:\n",
    "    MODEL = os.getenv(\"OPENAI_MODEL\") or \"gpt-4o\"\n",
    "    MAX_TOKENS = 16384\n",
    "\n",
    "print(f\"PDF: {PDF_PATH.name}\")\n",
    "print(f\"Provider: {PROVIDER}\")\n",
    "print(f\"Model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Initialize all components needed for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 0 image(s)\n",
      "Page 2: 0 image(s)\n",
      "Page 3: 0 image(s)\n",
      "Checking environment variables...\n",
      "GEMINI_API_KEY present: True\n",
      "OPENROUTER_API_KEY present: True\n",
      "\n",
      "Using Gemini API\n",
      "Extracted 0 images\n",
      "Encoded PDF (97000 characters)\n",
      "Initialized client\n"
     ]
    }
   ],
   "source": [
    "reference_json = load_reference_json(REFERENCE_JSON_PATH)\n",
    "example_json = select_reference_example(reference_json, example_title=None)\n",
    "\n",
    "extractor = ExtractImages(str(PDF_PATH), str(IMAGE_DIR))\n",
    "image_metadata = extractor.extract_img()\n",
    "extractor.save_metadata(str(IMAGE_DIR / \"metadata.json\"))\n",
    "image_metadata_text = format_image_metadata(image_metadata)\n",
    "\n",
    "pdf_b64 = encode_pdf_to_base64(PDF_PATH)\n",
    "\n",
    "# Debug: Check if environment variables are loaded\n",
    "print(f\"Checking environment variables...\")\n",
    "print(f\"GEMINI_API_KEY present: {bool(os.getenv('GEMINI_API_KEY'))}\")\n",
    "print(f\"OPENROUTER_API_KEY present: {bool(os.getenv('OPENROUTER_API_KEY'))}\")\n",
    "print()\n",
    "\n",
    "# Initialize the appropriate client based on provider\n",
    "if PROVIDER == \"gemini\":\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Set GEMINI_API_KEY in .env file\")\n",
    "    \n",
    "    client = GeminiClient(\n",
    "        model=MODEL,\n",
    "        api_key=api_key,\n",
    "        max_output_tokens=MAX_TOKENS,\n",
    "    )\n",
    "    print(f\"Using Gemini API\")\n",
    "    \n",
    "elif PROVIDER == \"openrouter\":\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Set OPENROUTER_API_KEY in .env file\")\n",
    "    \n",
    "    base_url = os.getenv(\"OPENROUTER_BASE_URL\") or \"https://openrouter.ai/api/v1\"\n",
    "    default_headers = {}\n",
    "    if referer := os.getenv(\"OPENROUTER_SITE_URL\"):\n",
    "        default_headers[\"HTTP-Referer\"] = referer\n",
    "    if app_name := os.getenv(\"OPENROUTER_APP_NAME\"):\n",
    "        default_headers[\"X-Title\"] = app_name\n",
    "    \n",
    "    client = OpenAIClient(\n",
    "        model=MODEL,\n",
    "        api_key=api_key,\n",
    "        base_url=base_url,\n",
    "        max_completion_tokens=MAX_TOKENS,\n",
    "        default_headers=default_headers,\n",
    "    )\n",
    "    print(f\"Using OpenRouter API\")\n",
    "    \n",
    "else:  # openai\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Set OPENAI_API_KEY in .env file\")\n",
    "    \n",
    "    base_url = os.getenv(\"OPENAI_BASE_URL\") or None\n",
    "    \n",
    "    client = OpenAIClient(\n",
    "        model=MODEL,\n",
    "        api_key=api_key,\n",
    "        base_url=base_url,\n",
    "        max_completion_tokens=MAX_TOKENS,\n",
    "    )\n",
    "    print(f\"Using OpenAI API\")\n",
    "\n",
    "print(f\"Extracted {len(image_metadata)} images\")\n",
    "print(f\"Encoded PDF ({len(pdf_b64)} characters)\")\n",
    "print(f\"Initialized client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Test All Strategies\n",
    "\n",
    "Tests the base strategy and and generates output files with different generation modes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/adaptive.md...\n",
      "Strategy: /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/adaptive.md\n",
      "Output: itell_input_adaptive.json\n",
      "\n",
      "Calling LLM with structured output...\n",
      "✓ Saved to /Users/kalidindiadithya/Documents/itell-volume-generation/results/itell_input_adaptive.json\n",
      "Valid structured output\n",
      "Pages: 1, Chunks: 5, Images: 0\n",
      "\n",
      "Testing /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/condensed.md...\n",
      "Strategy: /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/condensed.md\n",
      "Output: itell_input_condensed.json\n",
      "\n",
      "Calling LLM with structured output...\n",
      "✓ Saved to /Users/kalidindiadithya/Documents/itell-volume-generation/results/itell_input_condensed.json\n",
      "Valid structured output\n",
      "Pages: 1, Chunks: 7, Images: 0\n",
      "\n",
      "Testing /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/faithful.md...\n",
      "Strategy: /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/faithful.md\n",
      "Output: itell_input_faithful.json\n",
      "\n",
      "Calling LLM with structured output...\n",
      "✓ Saved to /Users/kalidindiadithya/Documents/itell-volume-generation/results/itell_input_faithful.json\n",
      "Valid structured output\n",
      "Pages: 1, Chunks: 5, Images: 0\n",
      "\n",
      "Testing /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/interaction-heavy.md...\n",
      "Strategy: /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/interaction-heavy.md\n",
      "Output: itell_input_interaction-heavy.json\n",
      "\n",
      "Calling LLM with structured output...\n",
      "✓ Saved to /Users/kalidindiadithya/Documents/itell-volume-generation/results/itell_input_interaction-heavy.json\n",
      "Valid structured output\n",
      "Pages: 1, Chunks: 11, Images: 0\n",
      "\n",
      "Testing /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/simplified.md...\n",
      "Strategy: /Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/simplified.md\n",
      "Output: itell_input_simplified.json\n",
      "\n",
      "Calling LLM with structured output...\n",
      "✓ Saved to /Users/kalidindiadithya/Documents/itell-volume-generation/results/itell_input_simplified.json\n",
      "Valid structured output\n",
      "Pages: 1, Chunks: 7, Images: 0\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Strategy                  Status                         Pages    Chunks   Images  \n",
      "--------------------------------------------------------------------------------\n",
      "/Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/adaptive.md Valid structured output        1        5        0       \n",
      "/Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/condensed.md Valid structured output        1        7        0       \n",
      "/Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/faithful.md Valid structured output        1        5        0       \n",
      "/Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/interaction-heavy.md Valid structured output        1        11       0       \n",
      "/Users/kalidindiadithya/Documents/itell-volume-generation/generation_modes_modular/simplified.md Valid structured output        1        7        0       \n",
      "================================================================================\n",
      "\n",
      "Results saved to: /Users/kalidindiadithya/Documents/itell-volume-generation/results\n"
     ]
    }
   ],
   "source": [
    "from pipeline.models import NewVolume\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for mode in GENERATION_MODES_PATH:\n",
    "    print(f\"Testing {mode}...\") \n",
    "    mode_name = mode.stem\n",
    "    base_text = load_guide_instructions(BASE_STRATEGY_PATH)\n",
    "    mode_text = load_guide_instructions(mode)\n",
    "    guide_text = base_text + \"\\n\\n\" + mode_text\n",
    "    prompt = build_conversion_prompt(guide_text, example_json, image_metadata_text=image_metadata_text)\n",
    "\n",
    "    output_filename = f\"itell_{PDF_NAME}_{mode_name}.json\"\n",
    "    output_path = project_root / \"results\" / output_filename\n",
    "\n",
    "    print(f\"Strategy: {mode}\")\n",
    "    print(f\"Output: {output_filename}\")\n",
    "    print(\"\\nCalling LLM with structured output...\")\n",
    "\n",
    "    try:\n",
    "        # Use structured output with Pydantic validation\n",
    "        result = client.generate_itell_structured(\n",
    "            pdf_filename=PDF_PATH.name,\n",
    "            pdf_base64=pdf_b64,\n",
    "            prompt=prompt,\n",
    "            response_format=NewVolume\n",
    "        )\n",
    "\n",
    "        # Convert Pydantic model to JSON with proper aliasing\n",
    "        result_json = result.model_dump_json(indent=2, by_alias=True)\n",
    "\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        output_path.write_text(result_json, encoding=\"utf-8\")\n",
    "\n",
    "        # Get stats from the Pydantic model\n",
    "        page_count = len(result.Pages)\n",
    "        chunk_count = sum(len(page.Content) for page in result.Pages)\n",
    "        status = \"Valid structured output\"\n",
    "\n",
    "        image_count = len(re.findall(r'!\\[.*?\\]\\(image_page_\\d+_\\d+\\)', result_json))\n",
    "\n",
    "        results_summary.append({\n",
    "            \"strategy\": mode,\n",
    "            \"output_file\": output_filename,\n",
    "            \"status\": status,\n",
    "            \"pages\": page_count,\n",
    "            \"chunks\": chunk_count,\n",
    "            \"images\": image_count\n",
    "        })\n",
    "\n",
    "        print(f\"✓ Saved to {output_path}\")\n",
    "        print(f\"{status}\")\n",
    "        print(f\"Pages: {page_count}, Chunks: {chunk_count}, Images: {image_count}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        results_summary.append({\n",
    "            \"mode\": mode,\n",
    "            \"output_file\": output_filename,\n",
    "            \"status\": f\"Error: {str(e)[:50]}...\",\n",
    "            \"pages\": \"N/A\",\n",
    "            \"chunks\": \"N/A\",\n",
    "            \"images\": \"N/A\"\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Strategy':<25} {'Status':<30} {'Pages':<8} {'Chunks':<8} {'Images':<8}\")\n",
    "print(\"-\"*80)\n",
    "for result in results_summary:\n",
    "    print(\n",
    "        f\"{str(result['strategy']):<25} {result['status']:<30} {str(result['pages']):<8} {str(result['chunks']):<8} {str(result['images']):<8}\"\n",
    "    )\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResults saved to: {project_root / 'results'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
